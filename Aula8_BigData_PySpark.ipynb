# ============================================
# Aula 8 - Big Data com PySpark
# Análise do California Housing Dataset
# ============================================

# ============================================
# PASSO 1: Instalar Java (requisito do Spark)
# ============================================

!apt-get install openjdk-11-jdk-headless -qq > /dev/null

# ============================================
# PASSO 2: Instalar PySpark
# ============================================

!pip install -q pyspark

# ============================================
# PASSO 3: Importar bibliotecas e criar sessão Spark
# ============================================

from pyspark.sql import SparkSession
import pyspark.sql.functions as F

# Criar sessão Spark
spark = SparkSession.builder.appName("Spark-ETL").getOrCreate()
spark

# ============================================
# PASSO 4: Carregar o dataset
# ============================================

data = spark.read.csv("sample_data/california_housing_train.csv", header=True)

print(f"The data contains: {data.count()} rows")
data.show()

# ============================================
# Explorar os dados básicos
# ============================================

# Estatísticas descritivas
data.describe().show()

# ou para mais detalhes:
data.summary().show()

# ============================================
# Selecionar colunas específicas
# ============================================

data.select("longitude", "latitude", "median_house_value").show(5)

# Renomear colunas na exibição
data.select(
    F.col("median_income").alias("income"),
    F.col("median_house_value").alias("house_value")
).show(5)

# ============================================
# Filtrar dados
# ============================================

# Filtro simples
data.filter(F.col("median_income") > 5).show(5)

# Filtros combinados
data.filter(
    (F.col("housing_median_age") > 30) & (F.col("total_rooms") < 50)
).show(5)

# ============================================
# Criar novas colunas
# ============================================

# Coluna calculada
data = data.withColumn("rooms_per_person", 
                       F.col("total_rooms") / F.col("population"))

data.select("total_rooms", "population", "rooms_per_person").show(5)

# Coluna com condições (when/otherwise)
data = data.withColumn("income_category", 
    F.when(F.col("median_income") > 6, "Alta")
    .when(F.col("median_income") > 3, "Média")
    .otherwise("Baixa")
)

data.select("median_income", "income_category").show(5)

# ============================================
# Agregações e agrupamentos
# ============================================

data.groupBy("income_category").agg(
    F.avg("median_house_value").alias("avg_value"),
    F.max("median_house_value").alias("max_value"),
    F.count("*").alias("count")
).orderBy(F.desc("avg_value")).show()

# ============================================
# Ordenação e limite
# ============================================

# Ordenar em ordem decrescente
data.orderBy(F.desc("median_house_value")).show(5)

# Ordenar e limitar
data.orderBy("housing_median_age").limit(5).show()

# ============================================
# Calcular correlações
# ============================================

print(data.corr("median_income", "median_house_value"))

# ============================================
# Usar SQL no PySpark
# ============================================

# Criar view temporária
data.createOrReplaceTempView("housing")

# Executar query SQL
spark.sql("""
SELECT income_category, 
       AVG(median_house_value) AS avg_value,
       COUNT(*) AS count
FROM housing
GROUP BY income_category
ORDER BY avg_value DESC
""").show()

# ============================================
# QUESTÃO 1: As casas mais antigas são necessariamente mais baratas?
# ============================================

data.orderBy(F.desc("housing_median_age")).select(
    "housing_median_age", 
    "median_house_value"
).show(10)

# ============================================
# QUESTÃO 2: Distribuição de valores por localização
# ============================================

data.groupBy("latitude").agg(
    F.avg("median_house_value").alias("avg_value"), 
    F.count("*").alias("count")
).orderBy(F.desc("avg_value")).show(50)

# ============================================
# QUESTÃO 3: Correlações
# ============================================

data.select(
    F.corr("total_rooms", "median_house_value").alias("corr_rooms_value"),
    F.corr("latitude", "median_house_value").alias("corr_lat_value"),
    F.corr("longitude", "median_house_value").alias("corr_long_value")
).show()
